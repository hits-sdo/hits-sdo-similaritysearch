{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hits-sdo/hits-sdo-similaritysearch/blob/ss_dataloader/search_simsiam/simsiam_example_notebook_HITS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hits-sdo/hits-sdo-similaritysearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpKcrCT_4Myq",
        "outputId": "80b863b2-3482-4afd-c386-3bcd51f295a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hits-sdo-similaritysearch'...\n",
            "remote: Enumerating objects: 323, done.\u001b[K\n",
            "remote: Counting objects: 100% (323/323), done.\u001b[K\n",
            "remote: Compressing objects: 100% (277/277), done.\u001b[K\n",
            "remote: Total 323 (delta 69), reused 278 (delta 38), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (323/323), 5.06 MiB | 16.08 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hits-sdo-similaritysearch/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm_gS85P9qv6",
        "outputId": "b5450d3c-4211-433b-f112-93b82cdb9ed4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hits-sdo-similaritysearch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "0ma6EWaJ9dxw",
        "outputId": "02672ecf-3d4a-414e-d6fd-ee4dca34a952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/hits-sdo/hits-sdo-packager.git@pip_nodata (from -r requirements.txt (line 11))\n",
            "  Cloning https://github.com/hits-sdo/hits-sdo-packager.git (to revision pip_nodata) to /tmp/pip-req-build-15evuggl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/hits-sdo/hits-sdo-packager.git /tmp/pip-req-build-15evuggl\n",
            "  Running command git checkout -b pip_nodata --track origin/pip_nodata\n",
            "  Switched to a new branch 'pip_nodata'\n",
            "  Branch 'pip_nodata' set up to track remote branch 'pip_nodata' from 'origin'.\n",
            "  Resolved https://github.com/hits-sdo/hits-sdo-packager.git to commit 187f561dec0ac179434fc78b7422436282f815ac\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lightning (from -r requirements.txt (line 6))\n",
            "  Downloading lightning-2.0.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightly (from -r requirements.txt (line 7))\n",
            "  Downloading lightly-1.4.5-py3-none-any.whl (653 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.4/653.4 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sunpy (from -r requirements.txt (line 8))\n",
            "  Downloading sunpy-4.1.6-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.5.3)\n",
            "Collecting wandb (from -r requirements.txt (line 10))\n",
            "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: PyYAML<8.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (6.0)\n",
            "Collecting arrow<3.0,>=1.2.0 (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (4.11.2)\n",
            "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (8.1.3)\n",
            "Collecting croniter<1.4.0,>=1.3.0 (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading croniter-1.3.14-py2.py3-none-any.whl (18 kB)\n",
            "Collecting dateutils<2.0 (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting deepdiff<8.0,>=5.7.0 (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading deepdiff-6.3.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<0.89.0,>=0.69.0 (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec<2024.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (2023.4.0)\n",
            "Collecting inquirer<5.0,>=2.10.0 (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
            "Collecting lightning-cloud>=0.5.34 (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading lightning_cloud-0.5.36-py3-none-any.whl (562 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities<2.0,>=0.7.0 (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: psutil<7.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (5.9.5)\n",
            "Requirement already satisfied: pydantic<4.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (1.10.7)\n",
            "Requirement already satisfied: requests<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (2.27.1)\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (13.3.4)\n",
            "Collecting starlette (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starsessions<2.0,>=1.2.1 (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: torch<4.0,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (2.0.1+cu118)\n",
            "Collecting torchmetrics<2.0,>=0.7.0 (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (4.65.0)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (5.7.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (1.26.15)\n",
            "Collecting uvicorn<2.0 (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning->-r requirements.txt (line 6)) (1.5.1)\n",
            "Collecting websockets<12.0 (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from lightly->-r requirements.txt (line 7)) (2022.12.7)\n",
            "Collecting hydra-core>=1.0.0 (from lightly->-r requirements.txt (line 7))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightly-utils~=0.0.0 (from lightly->-r requirements.txt (line 7))\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from lightly->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from lightly->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from lightly->-r requirements.txt (line 7)) (0.15.2+cu118)\n",
            "Requirement already satisfied: astropy>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from sunpy->-r requirements.txt (line 8)) (5.2.2)\n",
            "Collecting parfive[ftp]>=1.2.0 (from sunpy->-r requirements.txt (line 8))\n",
            "  Downloading parfive-2.0.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 9)) (2022.7.1)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb->-r requirements.txt (line 10))\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 10)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 10)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 10)) (3.20.3)\n",
            "Requirement already satisfied: pyerfa>=2.0 in /usr/local/lib/python3.10/dist-packages (from astropy>=4.2.1->sunpy->-r requirements.txt (line 8)) (2.0.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning->-r requirements.txt (line 6)) (2.4.1)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning->-r requirements.txt (line 6))\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting starlette (from lightning->-r requirements.txt (line 6))\n",
            "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->lightning->-r requirements.txt (line 6)) (3.6.2)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec<2024.0,>=2022.5.0->lightning->-r requirements.txt (line 6))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.4,>=2.2 (from hydra-core>=1.0.0->lightly->-r requirements.txt (line 7))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly->-r requirements.txt (line 7))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting blessed>=1.19.0 (from inquirer<5.0,>=2.10.0->lightning->-r requirements.txt (line 6))\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-editor>=1.0.4 (from inquirer<5.0,>=2.10.0->lightning->-r requirements.txt (line 6))\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning->-r requirements.txt (line 6))\n",
            "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<5.0->lightning->-r requirements.txt (line 6)) (2.1.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from lightly-utils~=0.0.0->lightly->-r requirements.txt (line 7)) (8.4.0)\n",
            "Collecting pyjwt (from lightning-cloud>=0.5.34->lightning->-r requirements.txt (line 6))\n",
            "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting python-multipart (from lightning-cloud>=0.5.34->lightning->-r requirements.txt (line 6))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aioftp>=0.17.1 (from parfive[ftp]>=1.2.0->sunpy->-r requirements.txt (line 8))\n",
            "  Downloading aioftp-0.21.4-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning->-r requirements.txt (line 6)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning->-r requirements.txt (line 6)) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning->-r requirements.txt (line 6)) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning->-r requirements.txt (line 6)) (2.14.0)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning->-r requirements.txt (line 6)) (2.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning->-r requirements.txt (line 6)) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning->-r requirements.txt (line 6)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning->-r requirements.txt (line 6)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning->-r requirements.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning->-r requirements.txt (line 6)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning->-r requirements.txt (line 6)) (16.0.5)\n",
            "Collecting h11>=0.8 (from uvicorn<2.0->lightning->-r requirements.txt (line 6))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning->-r requirements.txt (line 6)) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning->-r requirements.txt (line 6))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning->-r requirements.txt (line 6))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning->-r requirements.txt (line 6))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning->-r requirements.txt (line 6))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning->-r requirements.txt (line 6))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning->-r requirements.txt (line 6)) (0.2.6)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10))\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0,>=12.3.0->lightning->-r requirements.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.11.0->lightning->-r requirements.txt (line 6)) (1.3.0)\n",
            "Building wheels for collected packages: hits-sdo-packager, antlr4-python3-runtime, pathtools\n",
            "  Building wheel for hits-sdo-packager (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hits-sdo-packager: filename=hits_sdo_packager-0.1.0-py3-none-any.whl size=11098 sha256=b567b806bb9db276074621bf696326bac61ae10dd6a6164b4812c41516016815\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s17cluhf/wheels/2e/eb/6a/bd29fa0f13c312509ef59785fdf5297327b72cf53190878e91\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=ff0d79d88b0405eefc09b8ad2aabde83c5c2f27eb67b400cdffca8492b86668b\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=e0b19b77238202c04b18fb10e22046d54a39fd8b7e99221ec902ecb28ac89f78\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built hits-sdo-packager antlr4-python3-runtime pathtools\n",
            "Installing collected packages: python-editor, pathtools, antlr4-python3-runtime, websockets, smmap, setproctitle, sentry-sdk, readchar, python-multipart, pyjwt, ordered-set, omegaconf, multidict, lightning-utilities, lightly-utils, hits-sdo-packager, h11, frozenlist, docker-pycreds, blessed, async-timeout, aioftp, yarl, uvicorn, starlette, inquirer, hydra-core, gitdb, deepdiff, dateutils, croniter, arrow, aiosignal, starsessions, GitPython, fastapi, aiohttp, wandb, parfive, lightning-cloud, sunpy, torchmetrics, pytorch-lightning, lightning, lightly\n",
            "Successfully installed GitPython-3.1.31 aioftp-0.21.4 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 arrow-1.2.3 async-timeout-4.0.2 blessed-1.20.0 croniter-1.3.14 dateutils-0.6.12 deepdiff-6.3.0 docker-pycreds-0.4.0 fastapi-0.88.0 frozenlist-1.3.3 gitdb-4.0.10 h11-0.14.0 hits-sdo-packager-0.1.0 hydra-core-1.3.2 inquirer-3.1.3 lightly-1.4.5 lightly-utils-0.0.2 lightning-2.0.2 lightning-cloud-0.5.36 lightning-utilities-0.8.0 multidict-6.0.4 omegaconf-2.3.0 ordered-set-4.1.0 parfive-2.0.2 pathtools-0.1.2 pyjwt-2.7.0 python-editor-1.0.4 python-multipart-0.0.6 pytorch-lightning-2.0.2 readchar-4.0.5 sentry-sdk-1.23.1 setproctitle-1.3.2 smmap-5.0.0 starlette-0.22.0 starsessions-1.3.0 sunpy-4.1.6 torchmetrics-0.11.4 uvicorn-0.22.0 wandb-0.15.3 websockets-11.0.3 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from lightly.data import ImageCollateFunction, LightlyDataset, collate\n",
        "from lightly.loss import NegativeCosineSimilarity\n",
        "from lightly.models.modules.heads import SimSiamPredictionHead, SimSiamProjectionHead"
      ],
      "metadata": {
        "id": "sqEqKztpfVzo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download data\n",
        "!gdown 15C5spf1la7L09kvWXll2qt67Ec0rwLsY\n",
        "# unzip data\n",
        "!tar -zxf aia_171_color_1perMonth.tar.gz && rm aia_171_color_1perMonth.tar.gz"
      ],
      "metadata": {
        "id": "O_QRxTmgj-44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc68a73-7468-4386-fd13-9592f3ac49f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15C5spf1la7L09kvWXll2qt67Ec0rwLsY\n",
            "To: /content/aia_171_color_1perMonth.tar.gz\n",
            "100% 146M/146M [00:00<00:00, 173MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path_to_data = '/content/gdrive/MyDrive/HITS/aia_171_color_1perMonth/'\n",
        "path_to_data = '/content/aia_171_color_1perMonth'"
      ],
      "metadata": {
        "id": "q_S0omQr2tky"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_workers = 8 # How many process giving model to train -- similar to threading\n",
        "batch_size = 32 # A subset of files that the model sees to update it's parameters\n",
        "seed = 1 # Seed for random generator for reproducability\n",
        "epochs = 50 # How many times we go through our entire data set\n",
        "input_size = 128 #The number of pixels in x or y\n",
        "\n",
        "# dimension of the embeddings\n",
        "num_ftrs = 512 \n",
        "# dimension of the output of the prediction and projection heads\n",
        "out_dim = proj_hidden_dim = 512\n",
        "# the prediction head uses a bottleneck architecture\n",
        "pred_hidden_dim = 128"
      ],
      "metadata": {
        "id": "PXOSeFsifUSL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed torch and numpy \n",
        "# used for reproducibility in creating the model\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "TGu52CY1fk5q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the augmentations for self-supervised learning\n",
        "collate_fn = ImageCollateFunction(\n",
        "    input_size=input_size,\n",
        "    # require invariance to flips and rotations\n",
        "    hf_prob=0.5,\n",
        "    vf_prob=0.5,\n",
        "    rr_prob=0.5,\n",
        "    # satellite images are all taken from the same height\n",
        "    # so we use only slight random cropping\n",
        "    min_scale=0.5,\n",
        "    # use a weak color jitter for invariance w.r.t small color changes\n",
        "    cj_prob=0.2,\n",
        "    cj_bright=0.1,\n",
        "    cj_contrast=0.1,\n",
        "    cj_hue=0.1,\n",
        "    cj_sat=0.1,\n",
        ")\n",
        "\n",
        "#test for the collate function\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "img = np.zeros((128,128,3))\n",
        "img = torchvision.transforms.ToPILImage()(np.uint8(255*img))\n",
        "\n",
        "input = [(img, 0, 'my-image.png')]\n",
        "\n",
        "output = collate_fn(input)\n",
        "\n",
        "(img_t0, img_t1), label, filename = output\n",
        "\n",
        "# print(img_t0.shape, img_t1.shape)\n",
        "\n",
        "\n",
        "\n",
        "# create a lightly dataset for training, since the augmentations are handled\n",
        "# by the collate function, there is no need to apply additional ones here\n",
        "dataset_train_simsiam = LightlyDataset(input_dir=path_to_data)\n",
        "\n",
        "#3283 x 32 = 10506\n",
        "print(len(dataset_train_simsiam))\n",
        "# returns image, folder num, tile name\n",
        "print(dataset_train_simsiam[800])\n",
        "\n",
        "\n",
        "# create a dataloader for training\n",
        "dataloader_train_simsiam = torch.utils.data.DataLoader(\n",
        "    dataset_train_simsiam,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,           # data reshuffled at every epoch if True\n",
        "    collate_fn=collate_fn,  # constructs function\n",
        "    drop_last=True,         # If want to merge datasets (optional) - mostly used when batches are loaded from map-styled datasets.\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "# create a torchvision transformation for embedding the dataset after training\n",
        "# here, we resize the images to match the input size during training and apply\n",
        "# a normalization of the color channel based on statistics from imagenet\n",
        "test_transforms = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.Resize((input_size, input_size)),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(\n",
        "            mean=collate.imagenet_normalize[\"mean\"],\n",
        "            std=collate.imagenet_normalize[\"std\"],\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# create a lightly dataset for embedding\n",
        "dataset_test = LightlyDataset(input_dir=path_to_data, transform=test_transforms)\n",
        "\n",
        "# create a dataloader for embedding\n",
        "dataloader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdPjPH4iiQGI",
        "outputId": "3dc1d3b3-5ce7-44d4-b4e7-7ff42289f6bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105056\n",
            "(<PIL.Image.Image image mode=RGB size=128x128 at 0x7F74AF891060>, 1, '20100703_000036_aia.lev1_euv_12s_4k/tiles/20100703_000036_aia.lev1_euv_12s_4k_tile_1024_2944.jpg')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#test for the collate function\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "input = [(dataset_train_simsiam[800][0], 0, 'my-image.png')]\n",
        "\n",
        "output = collate_fn(input)\n",
        "\n",
        "(img_t0, img_t1), label, filename = output\n",
        "\n",
        "print(img_t0.shape, img_t1.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "bQgeMA5GGOBo",
        "outputId": "3e41a1df-85de-41aa-9495-5b8ab41914f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 128, 128]) torch.Size([1, 3, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.imshow(img_t0.permute(2, 3, 1, 0)[:,:,:,0],)\n"
      ],
      "metadata": {
        "id": "mjZt-skxGynZ",
        "outputId": "d0a89b31-59e4-4db4-cfa8-3e3e1e9c1574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.3652,  0.3652,  0.3481,  ...,  1.1015,  1.1358,  1.1529],\n",
              "          [ 0.7419,  0.6563,  0.5193,  ...,  1.1015,  1.1358,  1.1872],\n",
              "          [ 0.7933,  0.7248,  0.6049,  ...,  1.1015,  1.1358,  1.2043],\n",
              "          ...,\n",
              "          [ 0.4337,  0.4166,  0.4166,  ...,  1.2385,  1.2899,  1.3584],\n",
              "          [ 0.4166,  0.3994,  0.3994,  ...,  1.2728,  1.3070,  1.3584],\n",
              "          [ 0.3994,  0.3823,  0.3823,  ...,  1.2899,  1.3070,  1.3584]],\n",
              "\n",
              "         [[-0.4251, -0.4251, -0.4426,  ..., -0.0924, -0.0749, -0.0749],\n",
              "          [-0.2500, -0.3725, -0.5126,  ..., -0.1800, -0.1625, -0.1275],\n",
              "          [-0.2850, -0.3200, -0.4601,  ..., -0.1800, -0.1625, -0.1099],\n",
              "          ...,\n",
              "          [-0.4951, -0.5126, -0.5126,  ..., -0.0224, -0.0749, -0.0224],\n",
              "          [-0.5126, -0.5301, -0.5301,  ..., -0.0049, -0.0574, -0.0224],\n",
              "          [-0.5301, -0.5301, -0.5301,  ..., -0.0749, -0.0574, -0.0224]],\n",
              "\n",
              "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "          ...,\n",
              "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
              "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimSiam(nn.Module):\n",
        "    def __init__(self, backbone, num_ftrs, proj_hidden_dim, pred_hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = SimSiamProjectionHead(num_ftrs, proj_hidden_dim, out_dim)\n",
        "        self.prediction_head = SimSiamPredictionHead(out_dim, pred_hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # get representations\n",
        "        f = self.backbone(x).flatten(start_dim=1)\n",
        "        # get projections\n",
        "        z = self.projection_head(f)\n",
        "        # get predictions\n",
        "        p = self.prediction_head(z)\n",
        "        # stop gradient\n",
        "        z = z.detach()\n",
        "        return z, p\n",
        "\n",
        "\n",
        "# we use a pretrained resnet for this tutorial to speed\n",
        "# up training time but you can also train one from scratch\n",
        "resnet = torchvision.models.resnet18()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "model = SimSiam(backbone, num_ftrs, proj_hidden_dim, pred_hidden_dim, out_dim)"
      ],
      "metadata": {
        "id": "gZS_xfsqxOlC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SimSiam uses a symmetric negative cosine similarity loss\n",
        "criterion = NegativeCosineSimilarity()\n",
        "\n",
        "# scale the learning rate\n",
        "lr = 0.05 * batch_size / 256\n",
        "# use SGD with momentum and weight decay\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "q1uZbgoPzI12"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#true if currently have GPU\n",
        "torch.cuda.is_available()\n",
        "\n",
        "#check pgu count\n",
        "#not number of workers, that is seperate\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "id": "YMAH2ODzFUp2",
        "outputId": "70ee0bc2-9e6f-468a-803c-5e9c2d470312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "device = \"mps\" if torch.backends.mps.is_available() else device\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "avg_loss = 0.0\n",
        "avg_output_std = 0.0\n",
        "for e in range(epochs):\n",
        "    batch_count = 0\n",
        "    for (x0, x1), _, _ in dataloader_train_simsiam:\n",
        "        # move images to the gpu\n",
        "        x0 = x0.to(device)\n",
        "        x1 = x1.to(device)\n",
        "\n",
        "        # run the model on both transforms of the images\n",
        "        # we get projections (z0 and z1) and\n",
        "        # predictions (p0 and p1) as output\n",
        "        z0, p0 = model(x0)\n",
        "        z1, p1 = model(x1)\n",
        "\n",
        "        # apply the symmetric negative cosine similarity\n",
        "        # and run backpropagation\n",
        "        lo2,ss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # calculate the per-dimension standard deviation of the outputs\n",
        "        # we can use this later to check whether the embeddings are collapsing\n",
        "        output = p0.detach()\n",
        "        output = torch.nn.functional.normalize(output, dim=1)\n",
        "\n",
        "        output_std = torch.std(output, 0)\n",
        "        output_std = output_std.mean()\n",
        "        print(batch_count)\n",
        "        batch_count += 1\n",
        "        print(loss)\n",
        "        if(batch_count == 10):\n",
        "          break\n",
        "        # use moving averages to track the loss and standard deviation\n",
        "        w = 0.9\n",
        "        avg_loss = w * avg_loss + (1 - w) * loss.item()\n",
        "        avg_output_std = w * avg_output_std + (1 - w) * output_std.item()\n",
        "\n",
        "    # the level of collapse is large if the standard deviation of the l2\n",
        "    # normalized output is much smaller than 1 / sqrt(dim)\n",
        "    collapse_level = max(0.0, 1 - math.sqrt(out_dim) * avg_output_std)\n",
        "    # print intermediate results\n",
        "    print(\n",
        "        f\"[Epoch {e:3d}] \"\n",
        "        f\"Loss = {avg_loss:.2f} | \"\n",
        "        f\"Collapse Level: {collapse_level:.2f} / 1.00\"\n",
        "    )"
      ],
      "metadata": {
        "id": "pcDaEIek0E_c",
        "outputId": "96dc832b-1634-4ea3-f42e-904f044b2dda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "1\n",
            "tensor(-0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "2\n",
            "tensor(-0.0026, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "3\n",
            "tensor(-0.0089, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "4\n",
            "tensor(-0.0200, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "5\n",
            "tensor(-0.0088, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "6\n",
            "tensor(-0.0281, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "7\n",
            "tensor(-0.0162, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "8\n",
            "tensor(-0.0129, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "9\n",
            "tensor(-0.0213, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "[Epoch   0] Loss = -0.01 | Collapse Level: 0.50 / 1.00\n",
            "0\n",
            "tensor(-0.0343, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "1\n",
            "tensor(-0.0351, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "2\n",
            "tensor(-0.0324, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "3\n",
            "tensor(-0.0340, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "4\n",
            "tensor(-0.0411, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "5\n",
            "tensor(-0.0436, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "6\n",
            "tensor(-0.0476, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "7\n",
            "tensor(-0.0520, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "8\n",
            "tensor(-0.0592, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "9\n",
            "tensor(-0.0517, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "[Epoch   1] Loss = -0.03 | Collapse Level: 0.31 / 1.00\n",
            "0\n",
            "tensor(-0.0556, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "1\n",
            "tensor(-0.0654, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "2\n",
            "tensor(-0.0534, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "3\n",
            "tensor(-0.0684, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "4\n",
            "tensor(-0.0579, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "5\n",
            "tensor(-0.0694, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "6\n",
            "tensor(-0.0708, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "7\n",
            "tensor(-0.0830, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "8\n",
            "tensor(-0.0824, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "9\n",
            "tensor(-0.0768, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "[Epoch   2] Loss = -0.05 | Collapse Level: 0.24 / 1.00\n",
            "0\n",
            "tensor(-0.0932, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "1\n",
            "tensor(-0.1038, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "2\n",
            "tensor(-0.0868, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "3\n",
            "tensor(-0.0635, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "4\n",
            "tensor(-0.0925, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "5\n",
            "tensor(-0.1027, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "6\n",
            "tensor(-0.0861, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "7\n",
            "tensor(-0.1509, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "8\n",
            "tensor(-0.1381, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "9\n",
            "tensor(-0.1347, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "[Epoch   3] Loss = -0.09 | Collapse Level: 0.21 / 1.00\n",
            "0\n",
            "tensor(-0.1252, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "1\n",
            "tensor(-0.1440, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "2\n",
            "tensor(-0.1475, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "3\n",
            "tensor(-0.1384, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "4\n",
            "tensor(-0.1661, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "5\n",
            "tensor(-0.1643, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "6\n",
            "tensor(-0.1555, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "7\n",
            "tensor(-0.1756, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "8\n",
            "tensor(-0.1745, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "9\n",
            "tensor(-0.1734, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "[Epoch   4] Loss = -0.13 | Collapse Level: 0.21 / 1.00\n",
            "0\n",
            "tensor(-0.2253, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "1\n",
            "tensor(-0.1746, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "2\n",
            "tensor(-0.1854, device='cuda:0', grad_fn=<MulBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-bebd5d62ae27>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# we get projections (z0 and z1) and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# predictions (p0 and p1) as output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mz0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-dd89ff140d3b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# get representations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# get projections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    167\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                             return_indices=self.return_indices)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}